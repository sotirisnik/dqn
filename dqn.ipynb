{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare two function get_session and run_on_cpu. The first one uses cuda and we should allocate one fraction of memory otherwise it will allocate almost all available gpu. The second one is for running the operations in cpu only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    \n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "def run_on_cpu():\n",
    "\n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "    return tf.Session(config=config)\n",
    "    \n",
    "KTF.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Breakout Atari Game - BreakoutDeterministic-v4 use the skip frame that DeepMind used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-16 00:17:59,436] Making new env: BreakoutDeterministic-v4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make( 'BreakoutDeterministic-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess observation\n",
    "<p>1) Resize image</p>\n",
    "<p>2) Crop center image - do not keep score </p>\n",
    "<p>3) Grayscale image - reduce the rgb space to grayscale, save space </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9040ec6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def to_grayscale( observation ):\n",
    "    r, g, b = observation[:,:,0], observation[:,:,1], observation[:,:,2]\n",
    "    ret = 0.299 * r + 0.587 * g + 0.114 * b \n",
    "    return ( np.array( ret, dtype = np.uint8 ) )\n",
    "\n",
    "def preprocess_observation( observation ):\n",
    "    res = cv2.resize( observation, (84,110) )\n",
    "    crop = res[18:110-8:,:,:]\n",
    "    grayscale = to_grayscale( crop )\n",
    "    return ( grayscale )\n",
    "\n",
    "tmp = preprocess_observation( env.reset() )\n",
    "\n",
    "plt.imshow( tmp, cmap='gray' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model\n",
    "\n",
    "Our model consists of:\n",
    "    1 normalization layer - divide images by 255 which is the maximum value in grayscale images\n",
    "    3 convolutional layers - relu activation function\n",
    "    3 fully connected layers - relu activation function\n",
    "    1 output layer - linear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 4,208,164\n",
      "Trainable params: 4,208,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import initializers\n",
    "\n",
    "# Build model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "init_distr = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "#kernel_initializer=init_distr\n",
    "#32 filters of kernel(3,3), stride=4, input shape must be in format row, col, channels\n",
    "#init='uniform',\n",
    "\n",
    "model.add( Lambda(lambda x: x / 255.0, dtype='float32',  input_shape=(84,84,4)) )\n",
    "\n",
    "model.add( Conv2D(32, (8,8), strides=(4,4), padding='same' ) )\n",
    "model.add( Activation( 'relu' ) )\n",
    "\n",
    "model.add(Conv2D(64, (4,4), strides=(2,2), padding='same' ) )\n",
    "model.add( Activation( 'relu' ) )\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), padding='same' ) )\n",
    "model.add( Activation( 'relu' ) )\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add( Dense( env.action_space.n, activation='linear' ) )\n",
    "#model.compile(RMSprop(), 'MSE')\n",
    "#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "learning_rate = 1e-6#025\n",
    "model.compile(loss='mse', optimizer=Adam(lr=learning_rate), metrics=['accuracy'] )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 4,208,164\n",
      "Trainable params: 4,208,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build fixed model - that we will update during training.\n",
    "Afterwards we will update the weights when we save them on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build fixed\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_string = model.to_json()\n",
    "fixed_model = model_from_json(json_string)#does not load weights\n",
    "fixed_model.compile(loss='mse', optimizer=Adam(lr=learning_rate), metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observe total frames := 173\n",
      "Observe total frames := 400\n",
      "Observe total frames := 569\n",
      "Observe total frames := 756\n",
      "Observe total frames := 889\n",
      "Observe total frames := 1097\n",
      "Observe total frames := 1247\n",
      "Observe total frames := 1452\n",
      "Observe total frames := 1695\n",
      "Observe total frames := 1827\n",
      "Observe total frames := 2010\n",
      "Observe total frames := 2143\n",
      "Observe total frames := 2403\n",
      "Observe total frames := 2573\n",
      "Observe total frames := 2719\n",
      "Observe total frames := 2852\n",
      "Observe total frames := 2992\n",
      "Observe total frames := 3201\n",
      "Observe total frames := 3338\n",
      "Observe total frames := 3479\n",
      "Observe total frames := 3682\n",
      "Observe total frames := 3899\n",
      "Observe total frames := 4037\n",
      "Observe total frames := 4285\n",
      "Observe total frames := 4415\n",
      "Observe total frames := 4562\n",
      "Observe total frames := 4712\n",
      "Observe total frames := 4847\n",
      "Observe total frames := 5025\n",
      "Observe total frames := 5160\n",
      "Observe total frames := 5297\n",
      "Observe total frames := 5466\n",
      "Observe total frames := 5695\n",
      "Observe total frames := 5829\n",
      "Observe total frames := 6075\n",
      "Observe total frames := 6283\n",
      "Observe total frames := 6490\n",
      "Observe total frames := 6634\n",
      "Observe total frames := 6765\n",
      "Observe total frames := 6933\n",
      "Observe total frames := 7067\n",
      "Observe total frames := 7203\n",
      "Observe total frames := 7398\n",
      "Observe total frames := 7529\n",
      "Observe total frames := 7802\n",
      "Observe total frames := 7976\n",
      "Observe total frames := 8180\n",
      "Observe total frames := 8392\n",
      "Observe total frames := 8524\n",
      "Observe total frames := 8715\n",
      "Observe total frames := 8849\n",
      "Observe total frames := 8993\n",
      "Observe total frames := 9126\n",
      "Observe total frames := 9255\n",
      "Observe total frames := 9407\n",
      "Observe total frames := 9584\n",
      "Observe total frames := 9767\n",
      "Observe total frames := 10025\n",
      "Observe total frames := 10160\n",
      "Observe total frames := 10320\n",
      "Observe total frames := 10449\n",
      "Observe total frames := 10584\n",
      "Observe total frames := 10710\n",
      "Observe total frames := 10908\n",
      "Observe total frames := 11228\n",
      "Observe total frames := 11367\n",
      "Observe total frames := 11530\n",
      "Observe total frames := 11784\n",
      "Observe total frames := 11911\n",
      "Observe total frames := 12132\n",
      "Observe total frames := 12280\n",
      "Observe total frames := 12464\n",
      "Observe total frames := 12594\n",
      "Observe total frames := 12803\n",
      "Observe total frames := 12956\n",
      "Observe total frames := 13141\n",
      "Observe total frames := 13272\n",
      "Observe total frames := 13417\n",
      "Observe total frames := 13547\n",
      "Observe total frames := 13674\n",
      "Observe total frames := 13982\n",
      "Observe total frames := 14140\n",
      "Observe total frames := 14269\n",
      "Observe total frames := 14403\n",
      "Observe total frames := 14577\n",
      "Observe total frames := 14713\n",
      "Observe total frames := 14927\n",
      "Observe total frames := 15086\n",
      "Observe total frames := 15218\n",
      "Observe total frames := 15396\n",
      "Observe total frames := 15532\n",
      "Observe total frames := 15685\n",
      "Observe total frames := 15825\n",
      "Observe total frames := 16067\n",
      "Observe total frames := 16315\n",
      "Observe total frames := 16450\n",
      "Observe total frames := 16648\n",
      "Observe total frames := 16828\n",
      "Observe total frames := 16960\n",
      "Observe total frames := 17140\n",
      "Observe total frames := 17316\n",
      "Observe total frames := 17624\n",
      "Observe total frames := 17816\n",
      "Observe total frames := 18036\n",
      "Observe total frames := 18216\n",
      "Observe total frames := 18350\n",
      "Observe total frames := 18479\n",
      "Observe total frames := 18735\n",
      "Observe total frames := 18865\n",
      "Observe total frames := 19073\n",
      "Observe total frames := 19263\n",
      "Observe total frames := 19404\n",
      "Observe total frames := 19577\n",
      "Observe total frames := 19708\n",
      "Observe total frames := 19854\n",
      "Episode 1 | total reward := 1.0 | steps := 30 total frames := 30 | epsilon := 0.9999739000000009\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 1#0.999999#00025\n",
    "\n",
    "max_reward = 0.0\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start_episode = 1\n",
    "\n",
    "epsilon = 1\n",
    "epsilon_min = 0.1\n",
    "\n",
    "exploration_steps = 1000000\n",
    "\n",
    "#amount that we will reduce from epsilon each time we pick an action using our policy\n",
    "epsilon_discount = ( epsilon - epsilon_min ) / exploration_steps\n",
    "\n",
    "MAX_SIZE = 40000#capacity of deque\n",
    "MIN_MIN_SIZE = 20000#min size for replay in order to start replay which trains our model\n",
    "D = deque( maxlen=MAX_SIZE )#stores states that are used for during training\n",
    "\n",
    "frames = 0#keeps total frames so far\n",
    "\n",
    "def load_deque():\n",
    "    global D\n",
    "    pkl_file = open( 'mydeque.pkl', 'rb')\n",
    "    D = pickle.load( pkl_file )\n",
    "    pkl_file.close()\n",
    "\n",
    "def save_deque():\n",
    "    output = open( 'mydeque.pkl', 'wb' )\n",
    "    pickle.dump( D, output )\n",
    "    output.close()\n",
    "\n",
    "def load_dqn_model():\n",
    "    global model, fixed_model\n",
    "    from keras.models import model_from_json\n",
    "    # load json and create model\n",
    "    json_file = open('model_background.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"model_background.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    #model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=learning_rate), metrics=['accuracy'] )\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('model_background.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    fixed_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    fixed_model.load_weights(\"model_background.h5\")\n",
    "    print(\"Loaded model from disk - loaded to fixed\")\n",
    "    #model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    fixed_model.compile(loss='mse', optimizer=Adam(lr=learning_rate), metrics=['accuracy'] )\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "episodes = []\n",
    "rewards = []\n",
    "epsilons = []\n",
    "total_frames = []\n",
    "\n",
    "def save_train():\n",
    "\n",
    "    global episodes, rewards, epsilons, total_frames\n",
    "\n",
    "    #save [episodes, rewards, epsilons ] to csv file\n",
    "    d = {'episode': episodes, 'reward': rewards, 'epsilon': epsilons, 'total_frames': total_frames}\n",
    "    df = pd.DataFrame(data=d, index=None)\n",
    "\n",
    "    if not os.path.isfile('filename.csv'):\n",
    "        df.to_csv('filename.csv',header ='column_names', index=None)\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv('filename.csv',mode = 'a',header=False, index=None)\n",
    "\n",
    "    episodes = []\n",
    "    rewards = []\n",
    "    epsilons = []\n",
    "    total_frames = []\n",
    "\n",
    "    #save model to disk\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model_background.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model_background.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    #save deque to disk\n",
    "    #save_deque()\n",
    "\n",
    "def load_train():\n",
    "\n",
    "    global start_episode, epsilon, frames\n",
    "\n",
    "    #get last episode and epsilon\n",
    "    if not os.path.isfile('filename.csv'):\n",
    "        start_episode, epsilon = 1, 1\n",
    "    else: # else it exists so append without writing the header\n",
    "        df = pd.read_csv( 'filename.csv')\n",
    "\n",
    "        if len(df) == 0:\n",
    "            start_episode, epsilon, frames = 1, 1, 0\n",
    "        else:\n",
    "            epsilon = list( df['epsilon'].tail(1) )[0]\n",
    "            start_episode = list( df['episode'].tail(1) )[0] + 1\n",
    "            frames = list( df['total_frames'].tail(1) )[0]\n",
    "\n",
    "    if os.path.isfile('model_background.json'):\n",
    "        load_dqn_model()\n",
    "\n",
    "    #if os.path.isfile('mydeque.pkl'):\n",
    "        #load_deque()\n",
    "\n",
    "load_train()\n",
    "\n",
    "#print( start_episode, epsilon )\n",
    "#print( type( start_episode ) )\n",
    "#print( type( epsilon ) )\n",
    "#print( model.summary() )\n",
    "#print( D )\n",
    "\n",
    "total_observe = 12000#total_episodes - total games to play\n",
    "MIN_SIZE = 32#size of the minibatch - sample 32 samples\n",
    "\n",
    "observe_frame = 0\n",
    "\n",
    "#before starting training, we have to collect some samples - this stage is called \"observe\"\n",
    "def must_observe():\n",
    "    return ( observe_frame < MIN_MIN_SIZE )\n",
    "\n",
    "#replay trains our model\n",
    "def replay( ):\n",
    "\n",
    "    if len( D ) < MIN_MIN_SIZE:\n",
    "        return\n",
    "\n",
    "    #print( \"sample\" )\n",
    "\n",
    "    samples = random.sample( D, MIN_SIZE )\n",
    "\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    for sample in samples:\n",
    "\n",
    "        observation, reward, done, new_observation, action = sample\n",
    "\n",
    "        y = model.predict( observation.reshape(  ( 1, 84, 84, 4) ) )\n",
    "\n",
    "        Q_next = model.predict( new_observation.reshape(  ( 1, 84, 84, 4) ) )\n",
    "\n",
    "        reward = np.clip( reward, -1, 1 )\n",
    "\n",
    "        if done:\n",
    "            y[0,action] = reward\n",
    "        else:\n",
    "            y[0,action] = reward + gamma * ( np.max( Q_next[0]  ) )\n",
    "\n",
    "        #print( y )\n",
    "\n",
    "        neural_network_observation = observation.reshape(  ( 1, 84, 84, 4) )\n",
    "\n",
    "        all_x.append( neural_network_observation )\n",
    "        all_y.append( y )\n",
    "        #model.fit( neural_network_observation, y, epochs=1, verbose=0 )\n",
    "        #model.train_on_batch( neural_network_observation, y )\n",
    "\n",
    "    all_x = np.array( all_x ).reshape( (MIN_SIZE,84,84,4) )\n",
    "    all_y = np.array( all_y ).reshape( (MIN_SIZE,4) )\n",
    "\n",
    "    #model.train_on_batch( all_x, all_y )\n",
    "    fixed_model.fit(all_x, all_y, epochs=1, batch_size=MIN_SIZE, verbose=0)\n",
    "\n",
    "    del all_x, all_y\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "episode = start_episode\n",
    "\n",
    "while episode <= total_observe:#3600*5):\n",
    "\n",
    "    #start new game\n",
    "    \n",
    "    observation = env.reset()\n",
    "\n",
    "    observation = preprocess_observation( observation )\n",
    "\n",
    "    #build first state\n",
    "    recent_frames = deque(maxlen=4)\n",
    "\n",
    "    for i in range( 4 ):\n",
    "        recent_frames.append( observation )\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    #print( episode )\n",
    "\n",
    "    cur_lives = 5\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    action = 0\n",
    "\n",
    "    steps = 0\n",
    "\n",
    "    #play untill the game ends\n",
    "    while True:\n",
    "\n",
    "        #env.render()\n",
    "\n",
    "        stack_observation = np.stack(recent_frames,axis=0)\n",
    "\n",
    "        if must_observe():\n",
    "            observe_frame += 1\n",
    "\n",
    "        if must_observe() == False:\n",
    "            steps += 1\n",
    "\n",
    "        #pick an random action or use our policy\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            Q = model.predict( stack_observation.reshape(  ( 1, 84, 84, 4) ) )[0]\n",
    "            action = np.argmax( Q )\n",
    "        #step = 0\n",
    "\n",
    "        #execute selected action\n",
    "        new_observation, reward, done, info = env.step( action )\n",
    "\n",
    "        #build next stacked state\n",
    "        new_observation = preprocess_observation( new_observation )#apply preprocess\n",
    "\n",
    "        next_recent_frames = recent_frames.copy()\n",
    "        next_recent_frames.append( new_observation )\n",
    "        next_new_observation = np.stack(next_recent_frames,axis=0)\n",
    "\n",
    "        memory_reward = reward\n",
    "\n",
    "        if info['ale.lives'] < cur_lives:\n",
    "            cur_lives = info['ale.lives']\n",
    "            memory_reward = -1\n",
    "\n",
    "        #insert into deque - those samples are later used for training\n",
    "        D.append( ( stack_observation, memory_reward, done, next_new_observation, action ) )\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        replay()#train model\n",
    "\n",
    "        #if game is over\n",
    "        if done:\n",
    "            if must_observe() == False:\n",
    "                episodes.append( episode )\n",
    "                rewards.append( total_reward )\n",
    "                epsilons.append( epsilon )\n",
    "            D.append( ( stack_observation, -1, done, next_new_observation, action ) )\n",
    "            break\n",
    "\n",
    "        observation = new_observation\n",
    "\n",
    "        recent_frames.append( observation )\n",
    "\n",
    "        #we reduce the epsilon only when we have collected enough samples\n",
    "        if must_observe() == False:\n",
    "            epsilon = max( epsilon_min, epsilon - epsilon_discount )\n",
    "\n",
    "    if must_observe() == False:\n",
    "        frames += steps\n",
    "        total_frames.append( frames )\n",
    "        print( \"Episode \" + str(episode) + \" | total reward := \" + str(total_reward) + \" | steps := \" + str(steps) + \" total frames := \" + str(frames) + \" | epsilon := \" + str(epsilon) )\n",
    "    else:\n",
    "        print( \"Observe total frames := \" + str(observe_frame) )\n",
    "\n",
    "    #weights are saved per 10 games, also progress is saved on disk\n",
    "    if episode % 10 == 0 and episode > 1:\n",
    "        if must_observe() == False:\n",
    "            model.set_weights( fixed_model.get_weights() )\n",
    "            save_train()\n",
    "\n",
    "    if must_observe() == False:\n",
    "        episode += 1\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"total time is \" + str( end - start ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
